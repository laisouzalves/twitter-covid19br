{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Twitter Sentiment Analysis\n",
    "\n",
    "A construção da rede foi baseada em uma aula que tive da Udacity, do \"PyThorch Scholarship Challenge\", no qual aprendi sobre redes neurais profundas (CNNs, LSTMs, etc.) Não encontrei um link específico para o código desenvolvido por eles, mas vou deixar o notebook, que utilizei como base, junto dos arquivos. \n",
    "\n",
    "O meu objetivo aqui vai fazer uma análise exploratória dos dados e treinar um algoritmo capaz de classificar os sentimentos desses tweets em labels de 1 a 3, sendo:\n",
    "\n",
    "|1. Negativo |2. Neutro |3. Positivo |\n",
    "|:---|:---|:---|\n",
    "| Sarcasmo ou ironias negativas | Conselhos ou \"dicas\" | Preocupações positivas (_e.g._, desejar o bem) |\n",
    "| Reclamações | Propagandas | Otimismo |\n",
    "| Ameaças | Questionamentos | Paz |\n",
    "| Tristeza | Reflexões | Excitação |\n",
    "| Indignação | Curiosidades | Esperança |\n",
    "| Raiva | Comentários pensativos | Piadas de \"bom humor\" |\n",
    "| Críticas negativas | Rotina | Felicidade |\n",
    "| Tédio | | Sarcasmo ou Ironias positivas |\n",
    "| Pessimismo | | Gratidão |\n",
    "| Preocupações negativas | | Sonhos |\n",
    "| | | Campanhas à favor da quarentena |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Informações básicas sobre os dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Abrindo os arquivos:\n",
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('twitter_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>created_at</th>\n",
       "      <th>original_text</th>\n",
       "      <th>original_author</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>place</th>\n",
       "      <th>place_coord_boundaries</th>\n",
       "      <th>has_place</th>\n",
       "      <th>is_rt</th>\n",
       "      <th>Unnamed: 9</th>\n",
       "      <th>Unnamed: 10</th>\n",
       "      <th>Unnamed: 11</th>\n",
       "      <th>Unnamed: 12</th>\n",
       "      <th>Unnamed: 13</th>\n",
       "      <th>Unnamed: 14</th>\n",
       "      <th>Unnamed: 15</th>\n",
       "      <th>Unnamed: 16</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>Thu Mar 19 23:46:46 +0000 2020</td>\n",
       "      <td>Aproveite a quarentena e assista o Clíp do @Bl...</td>\n",
       "      <td>diegonogueira8</td>\n",
       "      <td>FakeNews, quarentena, coronavirus, coronavirus...</td>\n",
       "      <td>São Paulo/Brazil</td>\n",
       "      <td>[[-46.826039, -24.008814], [-46.365052, -24.00...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Thu Mar 19 23:46:36 +0000 2020</td>\n",
       "      <td>#jabá #resenha #blogues Quer uma #indicação de...</td>\n",
       "      <td>ticseducacao</td>\n",
       "      <td>jabá, resenha, blogues, indicação, livro, quar...</td>\n",
       "      <td>Rio de Janeiro, Brasil</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Thu Mar 19 23:46:34 +0000 2020</td>\n",
       "      <td>Sr. Presidente @jairbolsonaro, o senhor já pod...</td>\n",
       "      <td>Nelson_MCZ</td>\n",
       "      <td>quarentena</td>\n",
       "      <td>Brasil</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Thu Mar 19 23:46:14 +0000 2020</td>\n",
       "      <td>Vendo uma série para esquecer um pouco todo es...</td>\n",
       "      <td>jacksonjpsdb</td>\n",
       "      <td>Quarentena</td>\n",
       "      <td>Teresina Piauí Brasil</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>Thu Mar 19 23:46:11 +0000 2020</td>\n",
       "      <td>#FiqueEmCasa - Uma campanha CartaCapital https...</td>\n",
       "      <td>paulobretasjr</td>\n",
       "      <td>FiqueEmCasa</td>\n",
       "      <td>Rio de Janeiro</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment                      created_at  \\\n",
       "0          2  Thu Mar 19 23:46:46 +0000 2020   \n",
       "1          2  Thu Mar 19 23:46:36 +0000 2020   \n",
       "2          1  Thu Mar 19 23:46:34 +0000 2020   \n",
       "3          1  Thu Mar 19 23:46:14 +0000 2020   \n",
       "4          3  Thu Mar 19 23:46:11 +0000 2020   \n",
       "\n",
       "                                       original_text original_author  \\\n",
       "0  Aproveite a quarentena e assista o Clíp do @Bl...  diegonogueira8   \n",
       "1  #jabá #resenha #blogues Quer uma #indicação de...    ticseducacao   \n",
       "2  Sr. Presidente @jairbolsonaro, o senhor já pod...      Nelson_MCZ   \n",
       "3  Vendo uma série para esquecer um pouco todo es...    jacksonjpsdb   \n",
       "4  #FiqueEmCasa - Uma campanha CartaCapital https...   paulobretasjr   \n",
       "\n",
       "                                            hashtags                   place  \\\n",
       "0  FakeNews, quarentena, coronavirus, coronavirus...        São Paulo/Brazil   \n",
       "1  jabá, resenha, blogues, indicação, livro, quar...  Rio de Janeiro, Brasil   \n",
       "2                                         quarentena                  Brasil   \n",
       "3                                         Quarentena   Teresina Piauí Brasil   \n",
       "4                                        FiqueEmCasa          Rio de Janeiro   \n",
       "\n",
       "                              place_coord_boundaries has_place  is_rt  \\\n",
       "0  [[-46.826039, -24.008814], [-46.365052, -24.00...      True  False   \n",
       "1                                                NaN      True  False   \n",
       "2                                                NaN      True  False   \n",
       "3                                                NaN      True  False   \n",
       "4                                                NaN      True  False   \n",
       "\n",
       "  Unnamed: 9 Unnamed: 10 Unnamed: 11  Unnamed: 12  Unnamed: 13  Unnamed: 14  \\\n",
       "0        NaN         NaN         NaN          NaN          NaN          NaN   \n",
       "1        NaN         NaN         NaN          NaN          NaN          NaN   \n",
       "2        NaN         NaN         NaN          NaN          NaN          NaN   \n",
       "3        NaN         NaN         NaN          NaN          NaN          NaN   \n",
       "4        NaN         NaN         NaN          NaN          NaN          NaN   \n",
       "\n",
       "  Unnamed: 15 Unnamed: 16  \n",
       "0         NaN         NaN  \n",
       "1         NaN         NaN  \n",
       "2         NaN         NaN  \n",
       "3         NaN         NaN  \n",
       "4         NaN         NaN  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O total de twittes é de 10956.\n"
     ]
    }
   ],
   "source": [
    "total_twittes = data.shape[0]\n",
    "print(\"O total de twittes é de {}.\".format(total_twittes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment\n",
       "1        2329\n",
       "2        6037\n",
       "3        2587\n",
       "22          1\n",
       "1937        1\n",
       "35097       1\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.groupby(by=['sentiment'])['sentiment'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10953"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = data['sentiment'].isin([1, 2, 3])\n",
    "new_data = data[mask]\n",
    "new_data.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecionando os dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>original_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>Aproveite a quarentena e assista o Clíp do @Bl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>#jabá #resenha #blogues Quer uma #indicação de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Sr. Presidente @jairbolsonaro, o senhor já pod...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Vendo uma série para esquecer um pouco todo es...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>#FiqueEmCasa - Uma campanha CartaCapital https...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment                                      original_text\n",
       "0          2  Aproveite a quarentena e assista o Clíp do @Bl...\n",
       "1          2  #jabá #resenha #blogues Quer uma #indicação de...\n",
       "2          1  Sr. Presidente @jairbolsonaro, o senhor já pod...\n",
       "3          1  Vendo uma série para esquecer um pouco todo es...\n",
       "4          3  #FiqueEmCasa - Uma campanha CartaCapital https..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiments = new_data['sentiment']\n",
    "texts = new_data['original_text']\n",
    "\n",
    "df = pd.concat([sentiments, texts], axis = 1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10953"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fde954e4e48>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "sns.countplot(df['sentiment'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementação de uma RNN utilizando PyTorch\n",
    "\n",
    "Escolhi utilizar a biblioteca do PyTorch, baseada na biblioteca torch, para a implementação de uma rede neural. Esta biblioteca é utilizada para aplicações de deep learning e NLP.\n",
    ">O PyTorch é um software open source gratuito e foi inicialmente desenvolvido pela equipe de pesquisa de AI do Facebook.\n",
    "\n",
    "### Arquitetura da Rede\n",
    "\n",
    "Vou, então, implementar uma rede neural recorrente que classifica os sentimentos desses reviews. Na imagem abaixo podemos ter uma melhor ideia de como ela é composta (**Obs.**: No lugar das camadas Sigmoid, vamos utilizar uma camada totalmente conectada com ativação softmax):\n",
    "\n",
    "<img src=\"network_diagram.png\" width=40%>\n",
    "\n",
    "**Primeiro, vamos passar as palavras por uma camada de \"mergulho\" (embedding layer, em inglês)**\n",
    ">Precisamos dessa camada inicial pois temos milhares de palavras e precisamos ser mais eficientes nas representações de nossos dados de input. No nosso caso, esta camada é utilizada para fins de redução da dimensionalidade. Utilizando essa camada de mergulho, e deixando o algoritmo aprender sozinho uma nova representação, já é possível obter uma boa acurácia.\n",
    "\n",
    "**Após passarmos o input na camada de mergulho, os novos embeddings são passados pelas células LSTMs**\n",
    ">A LSTM é responsável por adicionar conexões recorrentes eficientes para o tratamento de textos, nos dando informações sobre a sequência de texto, ao invés de informações das palavras de forma isolada.\n",
    "\n",
    "**Por fim, a LSTM gera um output que é passado por uma última camada totalmente conectada**\n",
    ">A última camada vai ser composta por uma camada totalmente conectada (de 3 neurons), pois temos 3 tipos de inputs diferentes (negativo, neutro e positivo). Por fim, a função de ativação escolhida vai ser a função softmax, que é uma boa escolha para tratar a classificação multiclasse.\n",
    "\n",
    "(Considerando a imagem anterior, não é necessário se preocupar com as saídas da função de ativação, exceto para a **última**; podendo ignorar as restantes. Mais a frente, vamos calcular a loss function comparando o output do último passo com os labels de treinamento.)\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pré-processamento dos dados\n",
    "\n",
    "O primeiro passo antes de construir a rede neural é transformar os dados na melhor forma para inserir na rede. Como vamos usar camadas de embedding, vai ser necessário codificar cada palavra como um inteiro. Além disso, também é necessário \"limpar\" os ruídos.\n",
    "\n",
    "Os passos de processamento serão divididos em:\n",
    ">* Excluir os períodos e pontuações diversas (se houverem);\n",
    "* E combinar todas as palavras em uma grande string para codificar as palavras em vetores unitários."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arrumando as frases. Vamos substituir todas as maiusculas por\n",
    "# minusculas e tirar quaisquer pontuaçoes desnecessárias dos dados\n",
    "# (tanto de treinamento quanto de teste):\n",
    "\n",
    "import re # Esta é a biblioteca ReGex, usada para auxiliar a localização\n",
    "          # de padrões\n",
    "\n",
    "\n",
    "accent_map = {u'\\u00c0': u'A', u'\\u00c1': u'A', u'\\u00c2': u'A', u'\\u00c3': u'A', u'\\u00c4': u'A', u'\\u00c5': u'A', u'\\u00c6': u'A', u'\\u00c7': u'C', u'\\u00c8': u'E', u'\\u00c9': u'E', u'\\u00ca': u'E', u'\\u00cb': u'E', u'\\u00cc': u'I', u'\\u00cd': u'I', u'\\u00ce': u'I', u'\\u00cf': u'I', u'\\u00d0': u'D', u'\\u00d1': u'N', u'\\u00d2': u'O', u'\\u00d3': u'O', u'\\u00d4': u'O', u'\\u00d5': u'O', u'\\u00d6': u'O', u'\\u00d7': u'x', u'\\u00d8': u'0', u'\\u00d9': u'U', u'\\u00da': u'U', u'\\u00db': u'U', u'\\u00dc': u'U', U'\\u00dd': u'Y', u'\\u00df': u'B', u'\\u00e0': u'a', u'\\u00e1': u'a', u'\\u00e2': u'a', u'\\u00e3': u'a', u'\\u00e4': u'a', u'\\u00e5': u'a', u'\\u00e6': u'a', u'\\u00e7': u'c', u'\\u00e8': u'e', u'\\u00e9': u'e', u'\\u00ea': u'e', u'\\u00eb': u'e', u'\\u00ec': u'i', u'\\u00ed': u'i', u'\\u00ee': u'i', u'\\u00ef': u'i', u'\\u00f1': u'n', u'\\u00f2': u'o', u'\\u00f3': u'o', u'\\u00f4': u'o', u'\\u00f5': u'o', u'\\u00f6': u'o', u'\\u00f8': u'0', u'\\u00f9': u'u', u'\\u00fa': u'u', u'\\u00fb': u'u', u'\\u00fc': u'u'}\n",
    "\n",
    "\n",
    "def accent_remove(m):\n",
    "    return accent_map[m.group(0)]\n",
    "\n",
    "def remove_emoji(string):\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                           u\"\\U00002702-\\U000027B0\"\n",
    "                           u\"\\U000024C2-\\U0001F251\"\n",
    "                           \"]+\", flags=re.UNICODE)\n",
    "    return emoji_pattern.sub(r'', string)\n",
    "    \n",
    "def clean_tts(list_to_clean):\n",
    "    for idx, item in enumerate(list_to_clean):\n",
    "        # transforma tudo para str\n",
    "        list_to_clean[idx] = str(item)\n",
    "        # retira todo o link https:// do tuite\n",
    "        list_str = list_to_clean[idx].split()\n",
    "        string = ' '.join([word for word in list_str if not re.search('https://t.co', word)])\n",
    "        #remove acentos\n",
    "        list_to_clean[idx] = re.sub(u'([\\u00C0-\\u00FC])', accent_remove, string.encode().decode('utf-8'))\n",
    "        # remove emojis\n",
    "        string = list_to_clean[idx].encode('ascii', 'ignore').decode('ascii')\n",
    "        list_to_clean[idx] = remove_emoji(string)\n",
    "        # deixa tudo em caixa baixa\n",
    "        list_to_clean[idx] = list_to_clean[idx].lower()\n",
    "        # substitui o restante dos caracteres desnecessarios\n",
    "        string = list_to_clean[idx]\n",
    "        list_to_clean[idx] = re.sub('[…•\\-\\(\\)\\&]', '', string)\n",
    "        string = list_to_clean[idx]\n",
    "        list_to_clean[idx] = re.sub('\\W\\s-', '', string)\n",
    "        string = list_to_clean[idx]\n",
    "        list_to_clean[idx] = re.sub('[\"º°/_]', ' ', string)\n",
    "        # separa pontuações no final das palavras\n",
    "        char = '...'\n",
    "        string = list_to_clean[idx]\n",
    "        res = [i for j in string.split(char) for i in (j, char)][:-1] \n",
    "        list_to_clean[idx] = ' '.join(res)\n",
    "        char = '?'\n",
    "        string = list_to_clean[idx]\n",
    "        res = [i for j in string.split(char) for i in (j, char)][:-1] \n",
    "        list_to_clean[idx] = ' '.join(res) \n",
    "        char = '!'\n",
    "        string = list_to_clean[idx]\n",
    "        res = [i for j in string.split(char) for i in (j, char)][:-1] \n",
    "        list_to_clean[idx] = ' '.join(res)\n",
    "        char = '.'\n",
    "        string = list_to_clean[idx]\n",
    "        res = [i for j in string.split(char) for i in (j, char)][:-1] \n",
    "        list_to_clean[idx] = ' '.join(res)\n",
    "        char = ','\n",
    "        string = list_to_clean[idx]\n",
    "        res = [i for j in string.split(char) for i in (j, char)][:-1] \n",
    "        list_to_clean[idx] = ' '.join(res)\n",
    "        # remove palavras de comprimento menor que 3\n",
    "        string_list = list_to_clean[idx].split() \n",
    "        strings = [x for x in string_list if len(x)>2]\n",
    "        list_to_clean[idx] = ' '.join(strings)\n",
    "        # remove espaços desnecessarios\n",
    "        string_list = list_to_clean[idx].split()\n",
    "        list_to_clean[idx] = ' '.join(string_list)\n",
    "    return list_to_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['aproveite quarentena assista clip @blasthrash #fakenews #quarentena #coronavirus #coronavirusbrasil', '#jaba #resenha #blogues quer uma #indicacao bom #livro para estes tempos #quarentena', 'presidente @jairbolsonaro senhor pode convocar minha sogra para @minsaude 4dia #quarentena ela', 'vendo uma serie para esquecer pouco todo esse problema quanto estou #quarentena preventiva', '#fiqueemcasa uma campanha cartacapital via @youtube', 'dia #quarentena', '#witzel sensato atropele competencia p**** toda mesmo para impor #quarentena', 'porque nao pode quero fica rua #quarentena', 'partiu tocar ver friends nessa quarentena #quarentena', 'enquanto isso efeitos #quarentena chegou aqui nos vizinhos meu escritorio eles estao discutindo', 'todas atualizacoes que voce ouvir sobre numero pessoas infectadas por #coronavirus sarscov2 estao pelo men', 'dia quarentena descobri que moram outras pessoas aqui casa simpaticas ate #quarentena #coronavirus', 'queria umas cervejas agora #quarentena', 'desta forma programa viva rei tambem estara com suas edicoes suspensas ate tudo normalizar entretanto', 'nao vem nao que estou #quarentena', 'davi home office #quarentena #coronavirus #familia #filho #paidemeninos #amorincondicional #tudopramim', 'pensando farmacia comprar uma cartela benflogin #dicaszezo #quarentena', '#quarentena medindo com @tonimellx significado dos eventos historicos vida seu avo chegamos conclusao', 'obrigado vizinhos paneleiros esses 1015 min bater panela com voces tem sido fundamental pra minha saude menta', 'nos proximos dias vamos estar trabalhando casa momento muito cuidado zelo vamos nos resguardar nao']\n"
     ]
    }
   ],
   "source": [
    "texts_list = texts.to_list()\n",
    "\n",
    "clean_texts = clean_tts(texts_list)\n",
    "print(clean_texts[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 2, 1, 1, 3, 2, 3, 1, 2, 1]\n"
     ]
    }
   ],
   "source": [
    "sentiments = sentiments.to_list()\n",
    "\n",
    "print(sentiments[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['aproveite', 'quarentena', 'assista', 'clip', '@blasthrash', '#fakenews', '#quarentena', '#coronavirus', '#coronavirusbrasil', '#jaba', '#resenha', '#blogues', 'quer', 'uma', '#indicacao', 'bom', '#livro', 'para', 'estes', 'tempos', '#quarentena', 'presidente', '@jairbolsonaro', 'senhor', 'pode', 'convocar', 'minha', 'sogra', 'para', '@minsaude', '4dia', '#quarentena', 'ela', 'vendo', 'uma', 'serie', 'para', 'esquecer', 'pouco', 'todo', 'esse', 'problema', 'quanto', 'estou', '#quarentena', 'preventiva', '#fiqueemcasa', 'uma', 'campanha', 'cartacapital', 'via', '@youtube', 'dia', '#quarentena', '#witzel', 'sensato', 'atropele', 'competencia', 'p****', 'toda', 'mesmo', 'para', 'impor', '#quarentena', 'porque', 'nao', 'pode', 'quero', 'fica', 'rua', '#quarentena', 'partiu', 'tocar', 'ver', 'friends', 'nessa', 'quarentena', '#quarentena', 'enquanto', 'isso', 'efeitos', '#quarentena', 'chegou', 'aqui', 'nos', 'vizinhos', 'meu', 'escritorio', 'eles', 'estao', 'discutindo', 'todas', 'atualizacoes', 'que', 'voce', 'ouvir', 'sobre', 'numero', 'pessoas', 'infectadas']\n"
     ]
    }
   ],
   "source": [
    "all_text = []\n",
    "for idx, item in enumerate(clean_texts):\n",
    "    string = item\n",
    "\n",
    "    for idx, item in enumerate(string.split(' ')):\n",
    "        all_text.append(item)\n",
    "\n",
    "print(all_text[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Codificando as palavras\n",
    "\n",
    "Para utilizarmos a camada de mergulho (\"embedding layer\"), precisamos passar números inteiros na rede. Uma forma de fazer isso é criando um dicionário que mapeia palavras para números, tornando possível a conversão de cada uma das palavras dos reviews em números.\n",
    "\n",
    "Mais tarde, vamos acrescentar zeros (o chamado \"padding\") nos vetores de input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos então contar as palavras (para futuras análises - opcional)\n",
    "from collections import Counter\n",
    "\n",
    "counts = Counter(all_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de palavras em todos os tweets: 121649\n",
      "Total de palavras no vocabulario: 19933\n"
     ]
    }
   ],
   "source": [
    "# E criar um vocabulário, ordenado a partir das palavras mais faladas\n",
    "# Obs.: Este vocabulário é composto de palavras únicas, pois\n",
    "# o método Counter() conta as aparições de cada palavra e\n",
    "# retorna um vocabulário com o número de aparições e as strings\n",
    "vocabulary = sorted(counts, key=counts.get, reverse=True)\n",
    "print(\"Total de palavras em todos os tweets: {}\".format(len(all_text)))\n",
    "print(\"Total de palavras no vocabulario: {}\".format(len(vocabulary)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando um novo dicionário, que mapeia cada palavra (a partir da que\n",
    "# mais aparece) em números, começando de 1:\n",
    "vocabulary_to_int = {}\n",
    "int_to_vocabulary = {}\n",
    "for i, word in enumerate(vocabulary, 1):\n",
    "    vocabulary_to_int[word] = i\n",
    "    int_to_vocabulary[i] = word\n",
    "\n",
    "# Forma alternativa, utilizando dict comprehension\n",
    "# vocabulary_to_int = {word: i for i, word in enumerate(vocabulary, 1)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# E agora transformando cada review em números\n",
    "# e 'abusando' das list comprehensions:\n",
    "texts_int = []\n",
    "for review in clean_texts:\n",
    "    texts_int.append([vocabulary_to_int[word] for word in review.split()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Palavras únicas:  19933\n",
      "\n",
      "Review em formato token:\n",
      " [208, 12, 246, 4, 2461, 211, 63, 38, 455, 324, 55, 1, 2910]\n"
     ]
    }
   ],
   "source": [
    "# Conferindo:\n",
    "print(\"Palavras únicas: \", len(vocabulary_to_int))\n",
    "print()\n",
    "print(\"Review em formato token:\\n\", texts_int[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "\n",
      "[572, 8, 799, 7481, 7482, 2909, 1, 11, 47]\n"
     ]
    }
   ],
   "source": [
    "# E para uso futuro, vamos já deixar o vetor dos labels\n",
    "# de sentimentos pronto. O label da posição x ('encoded_label[x]')\n",
    "# corresponde ao review 'texts_set_int[x]':\n",
    "import numpy as np\n",
    "\n",
    "# Aqui vamos aproveitar para deixar as labels indexadas em 0, para evitar problemas futuros durante o treino da rede\n",
    "encoded_labels = np.array([(int(sentiments[i])-1) for i in range(1,len(sentiments))])\n",
    "                          \n",
    "print(encoded_labels[0])\n",
    "\n",
    "# E os dados de teste codificados:\n",
    "texts_set_int = []\n",
    "for review in texts_int:\n",
    "    texts_set_int.append(review)\n",
    "\n",
    "print()\n",
    "print(texts_set_int[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[300, 459, 513, 7537, 410, 168, 7538, 7539, 1]\n",
      "apenas consciencia #prevencao #ajuda #coronavirusbrazil #corona #pescaria #pesca #quarentena\n",
      "\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "# Para conferir se as conversões estão de acordo com o esperado...\n",
    "\n",
    "review_49 = texts_set_int[49] # review em formato token\n",
    "print(review_49)\n",
    "review_49_words = ' '.join([int_to_vocabulary[i] for i in review_49]) # refazendo a conversão\n",
    "print(review_49_words)\n",
    "print()\n",
    "print(sentiments[49])\n",
    "# Obs.: a partir daqui, os dados estão \"shifted\" por uma casa a menos,\n",
    "# isso pq nos dados anteriores tínhamos os cabeçalhos (aquele com os títulos\n",
    "# das colunas em formato string)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removendo outliers\n",
    "\n",
    "Um passo de pre-processamento adicional é o de padronizar nossos inputs. Isto é, nossa rede vai esperar como input um vetor de tamanho fixo. Assim, queremos formatar nossos reviews em um tamanho específico.\n",
    "\n",
    "Para fazer isso, podemos dividir o processo em dois passos:\n",
    "\n",
    "1. Retirar os reviews outliers (i.e., aqueles muito compridos ou muito curtos);\n",
    "2. Preencher (o famoso *padding*) ou truncar o restante dos dados, de forma a termos reviews com o mesmo tamanho."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número total de reviews: 10953\n",
      "Quantos reviews de tamanho nulo: 2\n",
      "Tamanho máximo de um review: 22\n"
     ]
    }
   ],
   "source": [
    "# Vamos procurar por reviews \"extremos\", aqueles\n",
    "# que podem \"bagunçar\" com o treinamento:\n",
    "\n",
    "tamanho_reviews = Counter([len(x) for x in texts_set_int]) # Dict: {objeto: contagem}\n",
    "print(\"Número total de reviews: {}\".format(len(texts_set_int)))\n",
    "print(\"Quantos reviews de tamanho nulo: {}\".format(tamanho_reviews[0]))\n",
    "print(\"Tamanho máximo de um review: {}\".format(max(tamanho_reviews)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({13: 1234, 14: 1200, 12: 1021, 15: 993, 11: 945, 10: 815, 9: 694, 16: 663, 8: 629, 7: 609, 5: 497, 6: 491, 17: 332, 4: 313, 3: 234, 18: 134, 2: 71, 19: 51, 20: 14, 1: 5, 21: 5, 0: 2, 22: 1})\n"
     ]
    }
   ],
   "source": [
    "print(tamanho_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "tamanho = sorted([key for key in tamanho_reviews.keys()])\n",
    "numero = [tamanho_reviews[lenght] for lenght in tamanho]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(tamanho, numero)\n",
    "plt.xlabel('Tamanho do tweet de treinamento')\n",
    "plt.ylabel('No. de tweets')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos então retirar os reviews de tamanho nulo e os\n",
    "# seus respectivos labels dos reviews:\n",
    "\n",
    "# Pegando os indices dos reviews de tamanho não nulo:\n",
    "non_zero_idx_train = [i for i, review in enumerate(texts_set_int) if len(review) != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de reviews antes da remoção dos reviews nulos:  10953\n",
      "Número de reviews após a remoção dos reviews nulos:  10951\n"
     ]
    }
   ],
   "source": [
    "# Removendo os reviews nulos e seus labels:\n",
    "train_set_int = [texts_set_int[i] for i in non_zero_idx_train]\n",
    "encoded_labels = np.array([encoded_labels[i] for i,j in enumerate(non_zero_idx_train)])\n",
    "\n",
    "print(\"Número de reviews antes da remoção dos reviews nulos: \", len(texts_set_int))\n",
    "print(\"Número de reviews após a remoção dos reviews nulos: \", len(train_set_int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10951\n",
      "10951\n"
     ]
    }
   ],
   "source": [
    "print(len(encoded_labels))\n",
    "print(len(train_set_int))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Realizando o preenchimento (*padding*)\n",
    "\n",
    "Para lidarmos com ambas as reviews (curtas e longas), a gente pode truncar ou preencher todos os nossos reviews, constringindo os reviews a um comprimento específico.\n",
    "\n",
    "Para reviews menores que um determinado comprimento `seq_length`, a gente preenche o vetor com 0's. Para reviews maiores que esse mesmo comprimento, a gente trunca ele nas primeiras palavras.\n",
    "\n",
    "Vamos considerar inicialmente um tamanho para a `seq_length` de 22, que foi o tamanho máximo encontrado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def padding_features(review_ints, seq_length):\n",
    "    ''' Retorna vetores (features) dos review_ints contidos\n",
    "        ou preenchidos até o limite de tamanho seq_length\n",
    "    '''\n",
    "    \n",
    "    # Aqui produzimos um vetor com a forma desejada de linhas x colunas:\n",
    "    features = np.zeros((len(review_ints),seq_length), dtype=int)\n",
    "    \n",
    "    # Para cada review:\n",
    "    for i, row in enumerate(review_ints):\n",
    "        features[i, -len(row):] = np.array(row[:seq_length])\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0    0    0    0    0    0    0    0    0    0    0    0    0  572\n",
      "     8  799 7481 7482 2909    1   11   47]\n",
      " [   0    0    0    0    0    0    0    0    0    0 7483 7484 7485  216\n",
      "    12 7486   66 7487    4 1305   89    1]\n",
      " [   0    0    0    0    0    0    0    0    0    0  146  293  532   62\n",
      "  7488   23 3631    4 1117 7489    1  144]]\n"
     ]
    }
   ],
   "source": [
    "seq_length = 22\n",
    "features_train = padding_features(train_set_int, seq_length=seq_length)\n",
    "\n",
    "# Para testar o código, podemos usar assert:\n",
    "# assert len(features) == len(train_set_int), \"As features devem ter o número de linhas igual ao numero de reviews\"\n",
    "# assert len(features[0]) == seq_length, \"Cada linha deve ter o mesmo comprimento\"\n",
    "\n",
    "print(features_train[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dividindo o conjunto de treinamento em Treinamento, Validação e Teste\n",
    "\n",
    "> Vamos agora dividir o conjunto de treinamento em três  grupos: um de validação, o outro para treinamento e um final para teste (Escolhi fazer isso para ser mais uma estapa de mensuração do código antes de submetê-lo ao benchmarking -- que é o conjunto de testes lá de cima que viemos trabalhando até aqui). Para isso:\n",
    "* Vamos criar um conjunto das features para treino (`train_x`) e um conjunto de suas labels (`train_y`);\n",
    "* Definir uma fração de *split* (`split_frac`) para ser a fração dos dados a serem **mantidos** no conjunto de treinamento. (Geralmente é de 0.8 ou 0.9);\n",
    "* O Restante é dividido no meio, em conjunto de validação (`val_x` e `val_y`) e conjunto de teste (`test_x` e `test_y`)."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Escolhendo a fração de split:\n",
    "split_frac = 0.7\n",
    "\n",
    "# Índice do split\n",
    "split_idx = int(len(features_train)*split_frac)\n",
    "\n",
    "# Separando o conjunto de treino\n",
    "train_x, remaining_x = features_train[:split_idx], features_train[split_idx:]\n",
    "train_y, remaining_y = encoded_labels[:split_idx], encoded_labels[split_idx:]\n",
    "\n",
    "# Índice de split do restante\n",
    "test_idx = int(len(remaining_x)*0.5)\n",
    "val_x, test_x = remaining_x[:test_idx], remaining_x[test_idx:]\n",
    "val_y, test_y = remaining_y[:test_idx], remaining_y[test_idx:]\n",
    "\n",
    "print(\"\\t\\t\\t\\tShapes das features:\")\n",
    "print(\"Conjunto de treino: \\t\\t{}\".format(train_x.shape), \n",
    "      \"\\nConjunto de Validação: \\t\\t{}\".format(val_x.shape),\n",
    "      \"\\nConjunto de teste: \\t\\t{}\".format(test_x.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Criando DataLoaders e Batching\n",
    "\n",
    "Agora estamos chegando na parte \"legal\" rsrs\n",
    "\n",
    "Agora que temos os nossos dados *bonitinhos* em mãos, precisamos de um método para criar nossos conjuntos de inputs de forma a minimizar o *overfitting* por conta de uma ordem específica presente nos dados.\n",
    "\n",
    "Uma forma é utilizando o [TensorDataset](https://pytorch.org/docs/stable/data.html#) para acessar os dados e criar os datasets. Utilizando a função *DataLoader* podemos criar pequenos *batchs*, escolhidos aleatoriamente dentre os dados."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "# Criando os datasets\n",
    "train_data = TensorDataset(torch.from_numpy(train_x), torch.from_numpy(train_y))\n",
    "valid_data = TensorDataset(torch.from_numpy(val_x), torch.from_numpy(val_y))\n",
    "test_data = TensorDataset(torch.from_numpy(test_x), torch.from_numpy(test_y))\n",
    "\n",
    "# Definindo o tamanho dos batchs\n",
    "batch_size = 128\n",
    "\n",
    "# Definindo os DataLoaders com o SHUFFLE ATIVADO (isso é importante!)\n",
    "train_loader = DataLoader(train_data, shuffle=True, batch_size=batch_size, drop_last=True)\n",
    "valid_loader = DataLoader(valid_data, shuffle=True, batch_size=batch_size, drop_last=True)\n",
    "test_loader = DataLoader(test_data, shuffle=True, batch_size=batch_size, drop_last=True)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Pegando um batch dos dados de treinamento:\n",
    "\n",
    "dataiter = iter(train_loader)\n",
    "sample_x, sample_y = dataiter.next()\n",
    "\n",
    "print('Tamanho do input da amostra: ', sample_x.size()) # batch_size, seq_length\n",
    "print('Input amostra: \\n', sample_x)\n",
    "print()\n",
    "print('Tamanho do label da amostra: ', sample_y.size()) # batch_size\n",
    "print('Label amostra: \\n', sample_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rede de Sentimentos usando PyTorch\n",
    "\n",
    "Relembrando, vamos dividir a nossa rede em três principais componentes (camadas):\n",
    "1. Uma [camada de *embedding*](https://pytorch.org/docs/stable/nn.html#embedding) que converte os nossos tokens de palavras (inteiros) em vetores de um tamanho específico;\n",
    "2. Uma camada de [LSTM](https://pytorch.org/docs/stable/nn.html#lstm), que é definida pelo tamanho do `hidden_state` e pelo número de camadas;\n",
    "3. Uma camada de output totalmente conectada que mapeia os outputs da camada LSTM aos outputs do tamanho desejado (`output_size`);\n",
    "4. E por fim uma função ativadação *softmax* que transforma os outputs em probabilidades de classe.\n",
    "\n",
    "### A camada de *embedding*\n",
    "\n",
    "Precisamos de uma camada de embedding pois temos mais de 19000 palavras no nosso vocabuário (este inclusive pode ser um problema no geral, pois essa quantidade é relativamente baixa em comparação às +170000 palavras não-obsoletas existentes em inglês).\n",
    "\n",
    "### As camadas da LSTM\n",
    "\n",
    "A LSTM vai receber um tamanho de input `input_size`, a dimensão da camada oculta `hidden_dim`, o número de camadas, uma probabilidade de dropout (no caso de múltiplas camadas) e um parâmetro de `batch_first`.\n",
    "\n",
    "Na maioria das vezes, a rede pode ter entre 2 e 3 camadas. Adicionar essas camadas permite um aprendizado de relações mais complexas pela rede."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Podemos adicionar este código para verificar se a máquina possui GPU disponível para uso\n",
    "train_on_gpu=torch.cuda.is_available()\n",
    "\n",
    "if(train_on_gpu):\n",
    "    print('Trainando na GPU.')\n",
    "else:\n",
    "    print('GPU nao disponivel, treinando na CPU.')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class SentimentRNN(nn.Module):\n",
    "    \"\"\"\n",
    "    Modelo de uma rede recorrente usada para realizar analise de sentimentos.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, vocab_size, output_size, embedding_dim, hidden_dim, n_layers, drop_prob=0.5):\n",
    "        # Aqui vamos inicializar a rede e os seus parâmetros \n",
    "        \n",
    "        super(SentimentRNN, self).__init__()\n",
    "\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "        self.hidden_dim = hidden_dim\n",
    "        \n",
    "        # Camadas de embedding e da LSTM\n",
    "        # Na LSTM, deve-se colocar batch_first pois os tensores\n",
    "        # de input e output tem a forma: (batch, seq, feature)\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, n_layers, \n",
    "                            dropout=drop_prob, batch_first=True)\n",
    "        \n",
    "        # Dropout\n",
    "        self.dropout = nn.Dropout(p=0.3)\n",
    "        \n",
    "        # Camada linear, dropout e softmax\n",
    "        self.fc = nn.Linear(hidden_dim, output_size)\n",
    "        self.log_softmax = nn.LogSoftmax(dim=1)\n",
    "        \n",
    "\n",
    "    def forward(self, x, hidden):\n",
    "        # Essa função é para realizar o forward pass do modelo no input e nos hidden states\n",
    "        \n",
    "        batch_size = x.size(0)\n",
    "\n",
    "        # Embeddings e lstm_out\n",
    "        embeds = self.embedding(x)\n",
    "        lstm_out, hidden = self.lstm(embeds, hidden)\n",
    "    \n",
    "        # Juntando os outputs da LSTM\n",
    "        lstm_out = lstm_out.contiguous().view(-1, self.hidden_dim)\n",
    "        \n",
    "        # Dropout e a camada totalmente conectada\n",
    "        out = self.dropout(lstm_out)\n",
    "        out = self.fc(out)\n",
    "        # Função LogSoftmax\n",
    "        soft_out = self.log_softmax(out)\n",
    "        \n",
    "        # Reshape para o batchfirst\n",
    "        soft_out = soft_out.view(batch_size, -1, self.output_size)\n",
    "        soft_out = soft_out[:, -1, :] # pega as labels(o output) da ultima posiçao te todas as linhas\n",
    "        \n",
    "        # Retorna o último output da softmax e do hidden state\n",
    "        return soft_out, hidden\n",
    "    \n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        # Essa função inicializa o hidden state\n",
    "        \n",
    "        # Cria dois novos tensores de tamanho n_layers x batch_size x hidden_dim,\n",
    "        # inicializados com zeros, pra o hidden state e a cell state da LSTM\n",
    "        weight = next(self.parameters()).detach()\n",
    "        \n",
    "        if (train_on_gpu):\n",
    "            hidden = (weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().cuda(),\n",
    "                  weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().cuda())\n",
    "        else:\n",
    "            hidden = (weight.new(self.n_layers, batch_size, self.hidden_dim).zero_(),\n",
    "                      weight.new(self.n_layers, batch_size, self.hidden_dim).zero_())\n",
    "\n",
    "        return hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instanciando a rede\n",
    "\n",
    "Vamos instanciar a rede definindo os parâmetros:\n",
    "* `vocab_size`: O tamanho do nosso vocabulário, ou o range dos valores do nosso input (tokens);\n",
    "* `output_size`: O tamanho do nosso output desejado; É o número de scores da nossa classe (1-3);\n",
    "* `embedding_dim`: Número de colunas na tabela do embedding; É o tamanho dos nossos embeddings;\n",
    "* `hidden_dim`: Número de unidades na camada oculta das nossas células de LSTM. Geralmente quanto maior, melhor a performance. Os tamanhos mais comuns são 128, 256, 512, etc.;\n",
    "* `n_layers`: É o número de camadas LSTM na rede. Geralmente ficam entre 1-3."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Vamos então instanciar a rede com os hyperparâmetros:\n",
    "vocab_size = len(vocabulary_to_int) + 1 # +1 pelo padding de 0's\n",
    "output_size = 3\n",
    "embedding_dim = 200\n",
    "hidden_dim = 256\n",
    "n_layers = 2"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "net = SentimentRNN(vocab_size, output_size, embedding_dim, hidden_dim, n_layers)\n",
    "\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Treinamento\n",
    "\n",
    "Vamos estar usando a [CrossEntropyLoss](https://pytorch.org/docs/stable/nn.html#crossentropyloss), a chamada *Cross Entropy Loss*. Ela foi desenhada para trabalhar com problemas de classificação com C classes. \n",
    "\n",
    "Nesta fase também precisamos de outros *hyperparameters*:\n",
    "* `lr`: a learning rate do nosso otimizador escolhido;\n",
    "* `epochs`: o número de vezes que vamos iterar pelo dataset de treinamento;\n",
    "* `clip`: que é o valor máximo do gradiente para evitar o problema do \"explosive gradients\"."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import torch.optim as optim\n",
    "# Funções de otimização e de loss\n",
    "lr = 0.001\n",
    "\n",
    "#criterion = nn.NLLLoss()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "#optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=lr, momentum=0.7)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "epochs = 100\n",
    "\n",
    "counter = 0\n",
    "print_every = 100\n",
    "clip = 5 # gradient clipping\n",
    "\n",
    "# Move o modelo para a GPU, se disponível\n",
    "# if(train_on_gpu):\n",
    "#     net.cuda()\n",
    "\n",
    "net.train()\n",
    "val_losses = []\n",
    "losses = []\n",
    "for e in range(epochs):\n",
    "    # Inicializando o hidden state\n",
    "    h = net.init_hidden(batch_size)\n",
    "\n",
    "    # Loop pelo batch\n",
    "    for inputs, labels in train_loader:\n",
    "        if( (inputs.shape[0],inputs.shape[1]) != (batch_size,seq_length)):\n",
    "            print(\"Pulando problema no Shape do Input: \",inputs.shape)\n",
    "            continue\n",
    "        counter += 1\n",
    "        \n",
    "        #if(train_on_gpu):\n",
    "        #    inputs, labels = inputs.cuda(), labels.cuda()\n",
    "\n",
    "        # Criando novo hidden state, para nao correr o risco de \n",
    "        # fazer o backprop por todo o historico de treinamento\n",
    "        h = tuple([each.detach() for each in h])\n",
    "\n",
    "        net.zero_grad()\n",
    "\n",
    "        output, h = net(inputs, h)\n",
    "        \n",
    "        loss = criterion(output.squeeze(), labels.long())\n",
    "        \n",
    "        losses.append(loss.item())\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        # `clip_grad_norm` ajuda a prevenir o problema do \"exploding gradient\" nas RNNs e LSTMs\n",
    "        nn.utils.clip_grad_norm_(net.parameters(), clip)\n",
    "        \n",
    "        optimizer.step()\n",
    "\n",
    "        # Estatisticas da loss\n",
    "        if counter % print_every == 0:\n",
    "            \n",
    "            val_h = net.init_hidden(batch_size)\n",
    "            net.eval()\n",
    "            \n",
    "            for inputs, labels in valid_loader:\n",
    "                \n",
    "                val_h = tuple([each.detach() for each in val_h])\n",
    "\n",
    "                #if(train_on_gpu):\n",
    "                #    inputs, labels = inputs.cuda(), labels.cuda()\n",
    "\n",
    "                output, val_h = net(inputs, val_h)\n",
    "                val_loss = criterion(output.squeeze(), labels.long())\n",
    "\n",
    "                val_losses.append(val_loss.item())\n",
    "                losses.append(loss.item())\n",
    "\n",
    "            net.train()\n",
    "            print(\"Epoch: {}/{}...\".format(e+1, epochs),\n",
    "                  \"Step: {}...\".format(counter),\n",
    "                  \"Loss: {:.6f}...\".format(loss.item()),\n",
    "                  \"Val Loss: {:.6f}\".format(np.mean(val_losses)))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "plt.plot(val_losses)\n",
    "plt.plot(losses)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Salvando o modelo:\n",
    "torch.save(net.state_dict(), 'sentiment_net.pt')\n",
    "\n",
    "# Para abrir:\n",
    "net.load_state_dict(torch.load('sentiment_net.pt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testando a rede\n",
    "\n",
    "Existem algumas formas de testar uma rede neural. Podemos testá-la através de:\n",
    "\n",
    "* **Teste de performance dos dados**: Primeiro vemos como nosso modelo performa em todos os `test_data` lá de cima, calculando o loss médio e a acurácia sobre os dados de teste;\n",
    "* **Inferência em dados gerados pelo usuário**: Podemos inserir um review por vez (sem o label) e ver o que o modelo treinado retorna.\n",
    "\n",
    "Aqui vou me ater apenas ao primeiro caso:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Pegando os dados de test_loss e de acurácia:\n",
    "test_loss = 0.0\n",
    "class_correct = list(0. for i in range(5))\n",
    "class_total = list(0. for i in range(5))\n",
    "\n",
    "h = net.init_hidden(batch_size)\n",
    "\n",
    "net.eval()\n",
    "for inputs, labels in test_loader:\n",
    "\n",
    "    h = tuple([each.data for each in h])\n",
    "\n",
    "#     if(train_on_gpu):\n",
    "#         inputs, labels = inputs.cuda(), labels.cuda()\n",
    "\n",
    "    output, h = net(inputs, h)\n",
    "\n",
    "    loss = criterion(output, labels.long())\n",
    "    \n",
    "    test_loss += loss.item()*inputs.size(0)\n",
    "    \n",
    "    # Convertendo as probabilidades do output para a classe prevista:\n",
    "    _, pred = torch.max(output, 1)\n",
    "    \n",
    "    # Comparando as previsões com o label verdadeiro:\n",
    "    correct = np.squeeze(pred.eq(labels.data.view_as(pred)))\n",
    "    \n",
    "    # Calculando a acurácia para cada classe de reviews\n",
    "    for i in range(len(labels)):\n",
    "        label = labels.data[i]\n",
    "        class_correct[label] += correct[i].item()\n",
    "        class_total[label] += 1\n",
    "\n",
    "\n",
    "### -- Status! -- ###\n",
    "# Calculando o test_loss medio\n",
    "test_loss = test_loss/len(test_loader.sampler)\n",
    "print('Test Loss: {:.6f}\\n'.format(test_loss))\n",
    "\n",
    "for i in range(3):\n",
    "    if class_total[i] > 0:\n",
    "        print('Test Accuracy of %5s: %2d%% (%2d/%2d)' % (\n",
    "            str(i), 100 * class_correct[i] / class_total[i],\n",
    "            np.sum(class_correct[i]), np.sum(class_total[i])))\n",
    "#     else:\n",
    "#         print('Test Accuracy of %3s: N/A (no training examples)' % (classes[i]))\n",
    "\n",
    "print('\\nTest Accuracy (Overall): %2d%% (%2d/%2d)' % (100. * np.sum(class_correct) / np.sum(class_total), np.sum(class_correct), np.sum(class_total)))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Test Loss: 0.877882\n",
    "\n",
    "Test Accuracy of     0:  0% ( 0/171)\n",
    "Test Accuracy of     1: 100% (634/634)\n",
    "Test Accuracy of     2:  0% ( 0/219)\n",
    "\n",
    "Test Accuracy (Overall): 61% (634/1024)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Realizei no total 2 treinos completos.\n",
    "\n",
    "Os dados sobre os treinos eu deixei no arquivo texto 'treino-sentiment-rnn.txt' para consultas.\n",
    "\n",
    "Apenas nos dois últimos treinos que realizei a verificação, sendo a melhor acurácia total obtida a de 59% (treino anterior a esse último). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Usando o keras ao invés do PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "seed = 42\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "from tensorflow import set_random_seed\n",
    "\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "set_random_seed(seed)\n",
    "\n",
    "from keras.preprocessing import sequence,text\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Dropout,Embedding,LSTM,Conv1D,GlobalMaxPooling1D,Flatten,MaxPooling1D,GRU,SpatialDropout1D,Bidirectional\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.utils import to_categorical\n",
    "from keras.losses import categorical_crossentropy\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, average_precision_score, f1_score, confusion_matrix, recall_score, precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def del_num(string):\n",
    "    string = str(string)\n",
    "    string = string.lower()\n",
    "    string = re.sub('\\W+\\s', '', string)\n",
    "    string = re.sub('\\d+', '', string)\n",
    "    string = re.sub('[\\(\\)/:*.-]', ' ', string)\n",
    "    string = string.split()\n",
    "    new_string = [i for i in string if len(i) > 2]\n",
    "    string = ' '.join(new_string)\n",
    "    return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "### SELECIONANDO OS DADOS DE TREINAMENTO E AS LABELS ###\n",
    "x = df['original_text'].apply(del_num)\n",
    "y = df['sentiment'].apply(lambda x: x-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweet:  #jabá #resenha #blogues quer uma #indicação bom #livro para estes tempos #quarentenahttps afqqzpdn \n",
      "Sentiment:  1\n"
     ]
    }
   ],
   "source": [
    "# Aqui eu já indexei os sentimentos em 0 (0 - negativo, 1- neutro, 2- positivo)\n",
    "print(\"Tweet: \", x[1],\"\\nSentiment: \", y[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state = 0, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    6037\n",
       "2    2587\n",
       "0    2329\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "### VERIFICANDO O BALANCEAMENTO DE CADA CLASSE DE INTERESSE ###\n",
    "sns.countplot(y)\n",
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1216</th>\n",
       "      <td>#danielnews #profdanielramos #pbh #alexandreka...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>729</th>\n",
       "      <td>minha pinscher fez mais pelo brasil que bolson...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9397</th>\n",
       "      <td>não existe ser mais resistente que cariocasobr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8452</th>\n",
       "      <td>aproveitando quarentena para assistir todos fi...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379</th>\n",
       "      <td>povo que sabe cantar tudo fazendo vídeoqueria ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          original_text  sentiment\n",
       "1216  #danielnews #profdanielramos #pbh #alexandreka...          1\n",
       "729   minha pinscher fez mais pelo brasil que bolson...          2\n",
       "9397  não existe ser mais resistente que cariocasobr...          1\n",
       "8452  aproveitando quarentena para assistir todos fi...          2\n",
       "379   povo que sabe cantar tudo fazendo vídeoqueria ...          1"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.utils import resample\n",
    "\n",
    "X = pd.concat([x_train, y_train], axis=1)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "category0 = X[X.sentiment==0]\n",
    "category1 = X[X.sentiment==1]\n",
    "category2 = X[X.sentiment==2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "number=len(category1)\n",
    "category0_upsampled = resample(category0,\n",
    "                          replace=True,\n",
    "                          n_samples=number,\n",
    "                          random_state=1)\n",
    "category1_upsampled = resample(category1,\n",
    "                          replace=True,\n",
    "                          n_samples=number,\n",
    "                          random_state=1)\n",
    "category2_upsampled = resample(category2,\n",
    "                          replace=True,\n",
    "                          n_samples=number,\n",
    "                          random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "resampled_data = pd.concat([category0_upsampled, category1_upsampled, category2_upsampled])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    14436\n",
       "1    14436\n",
       "0    14436\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resampled_data.sentiment.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = resampled_data['original_text']\n",
    "y_train = resampled_data['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fde6d94eb00>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZEAAAEGCAYAAACkQqisAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAAVSklEQVR4nO3df/BldX3f8efLXfFHlICyGtxds5u41SJGxR1AmWasJLDYxCUOtNBEVrOd7aRoNalNtHaklTDRiZUGo2SorIJxQIqmrClKdhBrawVZFPm1Ub5BC19B+dJFQmLULnn3j/tZvS53l+9+du+9fPf7fMzcuee8z+ec8zl8gdec8znn3FQVkiT1eMK0OyBJWrgMEUlSN0NEktTNEJEkdTNEJEndlk67A5N2xBFH1KpVq6bdDUlaUG666aYHqmrZ7vVFFyKrVq1i27Zt0+6GJC0oSf7PqLqXsyRJ3QwRSVI3Q0SS1M0QkSR1M0QkSd0MEUlSN0NEktTNEJEkdTNEJEndFt0T6/viZf/20ml34aB30x+eNZbt3v2uF41lu/pJz33nrWPZ7gnvP2Es29WPfeFNXzgg2/FMRJLUzRCRJHUbW4gk2Zzk/iS3jVj21iSV5Ig2nyQXJJlJckuSY4babkhyZ/tsGKq/LMmtbZ0LkmRcxyJJGm2cZyIfAdbtXkyyEvhl4O6h8inAmvbZBFzY2j4DOAc4DjgWOCfJ4W2dC1vbXes9al+SpPEaW4hU1eeBHSMWnQ/8LlBDtfXApTVwPXBYkiOBk4GtVbWjqh4EtgLr2rJDq+qLVVXApcCp4zoWSdJoEx0TSfIa4FtV9dXdFi0H7hman221vdVnR9T3tN9NSbYl2TY3N7cfRyBJGjaxEEnyVOAdwDtHLR5Rq476SFV1UVWtraq1y5Y96oe5JEmdJnkm8vPAauCrSb4JrAC+nORnGJxJrBxquwK49zHqK0bUJUkTNLEQqapbq+pZVbWqqlYxCIJjqurbwBbgrHaX1vHAQ1V1H3ANcFKSw9uA+knANW3Zw0mOb3dlnQVcNaljkSQNjPMW38uALwLPTzKbZONeml8N3AXMAP8F+FcAVbUDOBe4sX3e1WoAvwV8qK3zV8Cnx3EckqQ9G9trT6rqzMdYvmpouoCz99BuM7B5RH0bcPT+9VKStD98Yl2S1M0QkSR1M0QkSd0MEUlSN0NEktTNEJEkdTNEJEndDBFJUjdDRJLUzRCRJHUzRCRJ3QwRSVI3Q0SS1M0QkSR1M0QkSd0MEUlSN0NEktTNEJEkdTNEJEndxhYiSTYnuT/JbUO1P0zyl0luSfJnSQ4bWvb2JDNJvpbk5KH6ulabSfK2ofrqJDckuTPJx5McMq5jkSSNNs4zkY8A63arbQWOrqpfAL4OvB0gyVHAGcAL2zofTLIkyRLgA8ApwFHAma0twHuA86tqDfAgsHGMxyJJGmFsIVJVnwd27Fb7i6ra2WavB1a06fXA5VX1g6r6BjADHNs+M1V1V1X9ELgcWJ8kwKuAK9v6lwCnjutYJEmjTXNM5DeBT7fp5cA9Q8tmW21P9WcC3x0KpF11SdIETSVEkrwD2Al8bFdpRLPqqO9pf5uSbEuybW5ubl+7K0nag4mHSJINwK8Av15Vu/7HPwusHGq2Arh3L/UHgMOSLN2tPlJVXVRVa6tq7bJlyw7MgUiSJhsiSdYBvwe8pqq+N7RoC3BGkiclWQ2sAb4E3AisaXdiHcJg8H1LC5/rgNPa+huAqyZ1HJKkgXHe4nsZ8EXg+Ulmk2wE/hh4OrA1yc1J/gSgqm4HrgDuAD4DnF1Vj7QxjzcC1wDbgStaWxiE0e8kmWEwRnLxuI5FkjTa0sdu0qeqzhxR3uP/6KvqPOC8EfWrgatH1O9icPeWJGlKfGJdktTNEJEkdTNEJEndDBFJUjdDRJLUzRCRJHUzRCRJ3QwRSVI3Q0SS1M0QkSR1M0QkSd0MEUlSN0NEktTNEJEkdTNEJEndDBFJUjdDRJLUzRCRJHUzRCRJ3QwRSVK3sYVIks1J7k9y21DtGUm2JrmzfR/e6klyQZKZJLckOWZonQ2t/Z1JNgzVX5bk1rbOBUkyrmORJI02zjORjwDrdqu9Dbi2qtYA17Z5gFOANe2zCbgQBqEDnAMcBxwLnLMreFqbTUPr7b4vSdKYjS1EqurzwI7dyuuBS9r0JcCpQ/VLa+B64LAkRwInA1urakdVPQhsBda1ZYdW1RerqoBLh7YlSZqQSY+JPLuq7gNo389q9eXAPUPtZlttb/XZEfWRkmxKsi3Jtrm5uf0+CEnSwONlYH3UeEZ11Eeqqouqam1VrV22bFlnFyVJu5t0iHynXYqifd/f6rPAyqF2K4B7H6O+YkRdkjRBkw6RLcCuO6w2AFcN1c9qd2kdDzzULnddA5yU5PA2oH4ScE1b9nCS49tdWWcNbUuSNCFLx7XhJJcBrwSOSDLL4C6rdwNXJNkI3A2c3ppfDbwamAG+B7wBoKp2JDkXuLG1e1dV7Rqs/y0Gd4A9Bfh0+0iSJmhsIVJVZ+5h0Ykj2hZw9h62sxnYPKK+DTh6f/ooSdo/j5eBdUnSAmSISJK6GSKSpG6GiCSpmyEiSepmiEiSuhkikqRuhogkqZshIknqZohIkroZIpKkboaIJKmbISJJ6maISJK6GSKSpG6GiCSpmyEiSepmiEiSus0rRJJcO5+aJGlx2etvrCd5MvBU4IgkhwNpiw4FnjPmvkmSHuce60zkXwI3AS9o37s+VwEf6N1pkt9OcnuS25JcluTJSVYnuSHJnUk+nuSQ1vZJbX6mLV81tJ23t/rXkpzc2x9JUp+9hkhV/VFVrQbeWlU/V1Wr2+fFVfXHPTtMshz418DaqjoaWAKcAbwHOL+q1gAPAhvbKhuBB6vqecD5rR1JjmrrvRBYB3wwyZKePkmS+sxrTKSq3p/kFUn+eZKzdn32Y79LgackWcrgctl9wKuAK9vyS4BT2/T6Nk9bfmKStPrlVfWDqvoGMAMcux99kiTto72OieyS5KPAzwM3A4+0cgGX7usOq+pbSd4L3A38HfAXDC6RfbeqdrZms8DyNr0cuKetuzPJQ8AzW/36oU0Pr7N7/zcBmwCe+9zn7muXJUl7MK8QAdYCR1VV7e8O2wD9emA18F3gvwKnjGi6a1/Zw7I91R9drLoIuAhg7dq1+30MkqSB+T4nchvwMwdon78EfKOq5qrq/wGfBF4BHNYubwGsAO5t07PASoC2/KeBHcP1EetIkiZgviFyBHBHkmuSbNn16dzn3cDxSZ7axjZOBO4ArgNOa202MLgDDGBLm6ct/2w7I9oCnNHu3loNrAG+1NknSVKH+V7O+g8HaodVdUOSK4EvAzuBrzC41PTfgcuT/H6rXdxWuRj4aJIZBmcgZ7Tt3J7kCgYBtBM4u6oeQZI0MfMKkar6Hwdyp1V1DnDObuW7GHF3VVV9Hzh9D9s5DzjvQPZNkjR/870762F+PGh9CPBE4G+r6tBxdUyS9Pg33zORpw/PJzkVn8mQpEWv6y2+VfXfGDwcKElaxOZ7Oeu1Q7NPYPDciM9bSNIiN9+7s351aHon8E0GDwxKkhax+Y6JvGHcHZEkLTzz/VGqFUn+LMn9Sb6T5BNJVoy7c5Kkx7f5Dqx/mMET4s9h8JLDT7WaJGkRm2+ILKuqD1fVzvb5CLBsjP2SJC0A8w2RB5L8RpIl7fMbwP8dZ8ckSY9/8w2R3wT+KfBtBj8gdRrgYLskLXLzvcX3XGBDVT0IkOQZwHsZhIskaZGa75nIL+wKEICq2gG8dDxdkiQtFPMNkSe0XyQEfnQmMt+zGEnSQWq+QfCfgP/dfgekGIyP+Ap2SVrk5vvE+qVJtjF46WKA11bVHWPtmSTpcW/el6RaaBgckqQf6XoVvCRJYIhIkvaDISJJ6jaVEElyWJIrk/xlku1JXp7kGUm2JrmzfR/e2ibJBUlmktyS5Jih7Wxo7e9MsmEaxyJJi9m0zkT+CPhMVb0AeDGwHXgbcG1VrQGubfMApwBr2mcTcCH86FmVc4DjGPze+znDz7JIksZv4iGS5FDgF4GLAarqh1X1XQa/lHhJa3YJcGqbXg9cWgPXA4clORI4GdhaVTva0/RbgXUTPBRJWvSmcSbyc8Ac8OEkX0nyoSQ/BTy7qu4DaN/Pau2XA/cMrT/banuqP0qSTUm2Jdk2Nzd3YI9GkhaxaYTIUuAY4MKqeinwt/z40tUoGVGrvdQfXay6qKrWVtXaZcv8GRRJOlCmESKzwGxV3dDmr2QQKt9pl6lo3/cPtV85tP4K4N691CVJEzLxEKmqbwP3JHl+K53I4En4LcCuO6w2AFe16S3AWe0ureOBh9rlrmuAk5Ic3gbUT2o1SdKETOtNvG8CPpbkEOAuBj9w9QTgiiQbgbuB01vbq4FXAzPA91pbqmpHknOBG1u7d7VX1EuSJmQqIVJVNwNrRyw6cUTbAs7ew3Y2A5sPbO8kSfPlE+uSpG6GiCSpmyEiSepmiEiSuhkikqRuhogkqZshIknqZohIkroZIpKkboaIJKmbISJJ6maISJK6GSKSpG6GiCSpmyEiSepmiEiSuhkikqRuhogkqZshIknqNrUQSbIkyVeS/HmbX53khiR3Jvl4kkNa/UltfqYtXzW0jbe3+teSnDydI5GkxWuaZyJvBrYPzb8HOL+q1gAPAhtbfSPwYFU9Dzi/tSPJUcAZwAuBdcAHkyyZUN8lSUwpRJKsAP4J8KE2H+BVwJWtySXAqW16fZunLT+xtV8PXF5VP6iqbwAzwLGTOQJJEkzvTOQ/A78L/H2bfybw3ara2eZngeVtejlwD0Bb/lBr/6P6iHV+QpJNSbYl2TY3N3cgj0OSFrWJh0iSXwHur6qbhssjmtZjLNvbOj9ZrLqoqtZW1dply5btU38lSXu2dAr7PAF4TZJXA08GDmVwZnJYkqXtbGMFcG9rPwusBGaTLAV+GtgxVN9leB1J0gRM/Eykqt5eVSuqahWDgfHPVtWvA9cBp7VmG4Cr2vSWNk9b/tmqqlY/o929tRpYA3xpQochSWI6ZyJ78nvA5Ul+H/gKcHGrXwx8NMkMgzOQMwCq6vYkVwB3ADuBs6vqkcl3W5IWr6mGSFV9Dvhcm76LEXdXVdX3gdP3sP55wHnj66EkaW98Yl2S1M0QkSR1M0QkSd0MEUlSN0NEktTNEJEkdTNEJEndDBFJUjdDRJLUzRCRJHUzRCRJ3QwRSVI3Q0SS1M0QkSR1M0QkSd0MEUlSN0NEktTNEJEkdTNEJEndDBFJUreJh0iSlUmuS7I9ye1J3tzqz0iyNcmd7fvwVk+SC5LMJLklyTFD29rQ2t+ZZMOkj0WSFrtpnInsBP5NVf1D4Hjg7CRHAW8Drq2qNcC1bR7gFGBN+2wCLoRB6ADnAMcBxwLn7AoeSdJkTDxEquq+qvpym34Y2A4sB9YDl7RmlwCntun1wKU1cD1wWJIjgZOBrVW1o6oeBLYC6yZ4KJK06E11TCTJKuClwA3As6vqPhgEDfCs1mw5cM/QarOttqf6qP1sSrItyba5ubkDeQiStKhNLUSSPA34BPCWqvrrvTUdUau91B9drLqoqtZW1dply5bte2clSSNNJUSSPJFBgHysqj7Zyt9pl6lo3/e3+iywcmj1FcC9e6lLkiZkGndnBbgY2F5V7xtatAXYdYfVBuCqofpZ7S6t44GH2uWua4CTkhzeBtRPajVJ0oQsncI+TwBeB9ya5OZW+3fAu4ErkmwE7gZOb8uuBl4NzADfA94AUFU7kpwL3NjavauqdkzmECRJMIUQqar/xejxDIATR7Qv4Ow9bGszsPnA9U6StC98Yl2S1M0QkSR1M0QkSd0MEUlSN0NEktTNEJEkdTNEJEndDBFJUjdDRJLUzRCRJHUzRCRJ3QwRSVI3Q0SS1M0QkSR1M0QkSd0MEUlSN0NEktTNEJEkdTNEJEndDBFJUrcFHyJJ1iX5WpKZJG+bdn8kaTFZ0CGSZAnwAeAU4CjgzCRHTbdXkrR4LOgQAY4FZqrqrqr6IXA5sH7KfZKkRSNVNe0+dEtyGrCuqv5Fm38dcFxVvXG3dpuATW32+cDXJtrRyToCeGDanVAX/3YL28H+9/vZqlq2e3HpNHpyAGVE7VGpWFUXAReNvzvTl2RbVa2ddj+07/zbLWyL9e+30C9nzQIrh+ZXAPdOqS+StOgs9BC5EViTZHWSQ4AzgC1T7pMkLRoL+nJWVe1M8kbgGmAJsLmqbp9yt6ZtUVy2O0j5t1vYFuXfb0EPrEuSpmuhX86SJE2RISJJ6maIHCR8/cvClWRzkvuT3DbtvmjfJFmZ5Lok25PcnuTN0+7TpDkmchBor3/5OvDLDG57vhE4s6rumGrHNC9JfhH4G+DSqjp62v3R/CU5Ejiyqr6c5OnATcCpi+m/Pc9EDg6+/mUBq6rPAzum3Q/tu6q6r6q+3KYfBrYDy6fbq8kyRA4Oy4F7huZnWWT/IkvTlmQV8FLghun2ZLIMkYPDvF7/Imk8kjwN+ATwlqr662n3Z5IMkYODr3+RpiTJExkEyMeq6pPT7s+kGSIHB1//Ik1BkgAXA9ur6n3T7s80GCIHgaraCex6/ct24Apf/7JwJLkM+CLw/CSzSTZOu0+atxOA1wGvSnJz+7x62p2aJG/xlSR180xEktTNEJEkdTNEJEndDBFJUjdDRJLUzRCRJiTJS4Zv/0zymnG/cTnJK5O8Ypz70OJmiEiT8xLgRyFSVVuq6t1j3ucrAUNEY+NzItI8JPkp4AoGr5RZApwLzADvA54GPAC8vqruS/I5Bi/h+8fAYcDGNj8DPAX4FvAHbXptVb0xyUeAvwNeAPws8AZgA/By4Iaqen3rx0nAfwSeBPwV8Iaq+psk3wQuAX4VeCJwOvB94HrgEWAOeFNV/c9x/PPR4uWZiDQ/64B7q+rF7Tc/PgO8Hzitql4GbAbOG2q/tKqOBd4CnNNe0f9O4ONV9ZKq+viIfRwOvAr4beBTwPnAC4EXtUthRwD/HvilqjoG2Ab8ztD6D7T6hcBbq+qbwJ8A57d9GiA64JZOuwPSAnEr8N4k7wH+HHgQOBrYOnh9EkuA+4ba73oR303Aqnnu41NVVUluBb5TVbcCJLm9bWMFcBTwhbbPQxi8LmXUPl+7D8cmdTNEpHmoqq8neRmDMY0/ALYCt1fVy/ewyg/a9yPM/7+zXev8/dD0rvmlbVtbq+rMA7hPab94OUuahyTPAb5XVX8KvBc4DliW5OVt+ROTvPAxNvMw8PT96Mb1wAlJntf2+dQk/2DM+5T2yhCR5udFwJeS3Ay8g8H4xmnAe5J8FbiZx74L6jrgqPam13+2rx2oqjng9cBlSW5hECoveIzVPgX8WtvnP9rXfUqPxbuzJEndPBORJHUzRCRJ3QwRSVI3Q0SS1M0QkSR1M0QkSd0MEUlSt/8PS9gsSVffYQoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "tam_vocab = len(vocabulary)\n",
    "tokenizer = Tokenizer(num_words=tam_vocab)\n",
    "tokenizer.fit_on_texts(list(x_train))\n",
    "tokenizer.fit_on_texts(list(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43308\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[    0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     4,   226,    29,   446,   141,    53,    35,\n",
       "           13,    11,    57,  7072],\n",
       "       [    0,     0,     0,     0,   145,   286,  3341,  3959,     2,\n",
       "          176,   639,   196,   847,  3960,   640,     2,   136,   194,\n",
       "           15,   629,   174,  3961],\n",
       "       [    0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,   104,   125,     5,   141,\n",
       "            2,   769,     1,     3],\n",
       "       [    0,     0,     0,     0,    16,  1209,    21,  1343,   162,\n",
       "         2016,    10, 12165,    16,   316,   212,   524,    19,   144,\n",
       "          459,    93,  2017,     1],\n",
       "       [    0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,   235,   385,    15,   619,   290,\n",
       "           27,   308,     1,    13]], dtype=int32)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = tokenizer.texts_to_sequences(x_train)\n",
    "X_test = tokenizer.texts_to_sequences(x_test)\n",
    "X_train = pad_sequences(X_train, maxlen=22)\n",
    "X_test = pad_sequences(X_test, maxlen=22)\n",
    "print(len(X_train))\n",
    "X_train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43308\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(43308, 3)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train = to_categorical(y_train.values)\n",
    "print(len(Y_train))\n",
    "Y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(43308, 22) (43308, 3) (2191, 22) (2191,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, Y_train.shape, X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, val_x, train_y, val_y = train_test_split(X_train, Y_train, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features = len(vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, None, 256)         5102848   \n",
      "_________________________________________________________________\n",
      "lstm_5 (LSTM)                (None, None, 256)         525312    \n",
      "_________________________________________________________________\n",
      "lstm_6 (LSTM)                (None, 512)               1574912   \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 3)                 1539      \n",
      "=================================================================\n",
      "Total params: 7,204,611\n",
      "Trainable params: 7,204,611\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model=Sequential()\n",
    "model.add(Embedding(max_features,512,mask_zero=True))\n",
    "model.add(LSTM(256,dropout=0.4, recurrent_dropout=0.4,return_sequences=True))\n",
    "model.add(LSTM(512,dropout=0.5, recurrent_dropout=0.5,return_sequences=False))\n",
    "model.add(Dense(3,activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy',optimizer=Adam(lr=0.0001),metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 34646 samples, validate on 8662 samples\n",
      "Epoch 1/50\n",
      "34646/34646 [==============================] - 229s 7ms/step - loss: 0.5314 - accuracy: 0.7658 - val_loss: 0.1574 - val_accuracy: 0.9501\n",
      "Epoch 2/50\n",
      "34646/34646 [==============================] - 217s 6ms/step - loss: 0.0870 - accuracy: 0.9717 - val_loss: 0.0759 - val_accuracy: 0.9770\n",
      "Epoch 3/50\n",
      "34646/34646 [==============================] - 218s 6ms/step - loss: 0.0419 - accuracy: 0.9866 - val_loss: 0.0655 - val_accuracy: 0.9834\n",
      "Epoch 4/50\n",
      "34646/34646 [==============================] - 221s 6ms/step - loss: 0.0280 - accuracy: 0.9914 - val_loss: 0.0662 - val_accuracy: 0.9850\n",
      "Epoch 5/50\n",
      "34646/34646 [==============================] - 214s 6ms/step - loss: 0.0205 - accuracy: 0.9938 - val_loss: 0.0664 - val_accuracy: 0.9850\n",
      "Epoch 6/50\n",
      "34646/34646 [==============================] - 212s 6ms/step - loss: 0.0182 - accuracy: 0.9942 - val_loss: 0.0695 - val_accuracy: 0.9863\n",
      "Epoch 7/50\n",
      "34646/34646 [==============================] - 211s 6ms/step - loss: 0.0169 - accuracy: 0.9948 - val_loss: 0.0622 - val_accuracy: 0.9873\n",
      "Epoch 8/50\n",
      "34646/34646 [==============================] - 213s 6ms/step - loss: 0.0118 - accuracy: 0.9966 - val_loss: 0.0676 - val_accuracy: 0.9872\n",
      "Epoch 9/50\n",
      "34646/34646 [==============================] - 212s 6ms/step - loss: 0.0098 - accuracy: 0.9966 - val_loss: 0.0760 - val_accuracy: 0.9889\n",
      "Epoch 10/50\n",
      "34646/34646 [==============================] - 211s 6ms/step - loss: 0.0111 - accuracy: 0.9964 - val_loss: 0.0795 - val_accuracy: 0.9863\n",
      "Epoch 11/50\n",
      "34646/34646 [==============================] - 212s 6ms/step - loss: 0.0077 - accuracy: 0.9976 - val_loss: 0.0711 - val_accuracy: 0.9887\n",
      "Epoch 12/50\n",
      "34646/34646 [==============================] - 211s 6ms/step - loss: 0.0103 - accuracy: 0.9965 - val_loss: 0.0690 - val_accuracy: 0.9876\n",
      "Epoch 13/50\n",
      "34646/34646 [==============================] - 212s 6ms/step - loss: 0.0071 - accuracy: 0.9975 - val_loss: 0.0789 - val_accuracy: 0.9882\n",
      "Epoch 14/50\n",
      "34646/34646 [==============================] - 213s 6ms/step - loss: 0.0077 - accuracy: 0.9974 - val_loss: 0.0684 - val_accuracy: 0.9897\n",
      "Epoch 15/50\n",
      "34646/34646 [==============================] - 216s 6ms/step - loss: 0.0070 - accuracy: 0.9978 - val_loss: 0.0800 - val_accuracy: 0.9873\n",
      "Epoch 16/50\n",
      "34646/34646 [==============================] - 211s 6ms/step - loss: 0.0063 - accuracy: 0.9980 - val_loss: 0.0664 - val_accuracy: 0.9898\n",
      "Epoch 17/50\n",
      "34646/34646 [==============================] - 212s 6ms/step - loss: 0.0037 - accuracy: 0.9988 - val_loss: 0.0858 - val_accuracy: 0.9885\n",
      "Epoch 18/50\n",
      "34646/34646 [==============================] - 211s 6ms/step - loss: 0.0038 - accuracy: 0.9988 - val_loss: 0.0907 - val_accuracy: 0.9886\n",
      "Epoch 19/50\n",
      "34646/34646 [==============================] - 212s 6ms/step - loss: 0.0059 - accuracy: 0.9981 - val_loss: 0.0771 - val_accuracy: 0.9875\n",
      "Epoch 20/50\n",
      "34646/34646 [==============================] - 212s 6ms/step - loss: 0.0053 - accuracy: 0.9981 - val_loss: 0.0856 - val_accuracy: 0.9896\n",
      "Epoch 21/50\n",
      "34646/34646 [==============================] - 212s 6ms/step - loss: 0.0048 - accuracy: 0.9984 - val_loss: 0.0777 - val_accuracy: 0.9885\n",
      "Epoch 22/50\n",
      "34646/34646 [==============================] - 211s 6ms/step - loss: 0.0030 - accuracy: 0.9987 - val_loss: 0.0832 - val_accuracy: 0.9887\n",
      "Epoch 23/50\n",
      "34646/34646 [==============================] - 216s 6ms/step - loss: 0.0030 - accuracy: 0.9989 - val_loss: 0.0925 - val_accuracy: 0.9881\n",
      "Epoch 24/50\n",
      "34646/34646 [==============================] - 238s 7ms/step - loss: 0.0039 - accuracy: 0.9986 - val_loss: 0.0890 - val_accuracy: 0.9875\n",
      "Epoch 25/50\n",
      "34646/34646 [==============================] - 225s 6ms/step - loss: 0.0043 - accuracy: 0.9984 - val_loss: 0.0817 - val_accuracy: 0.9891\n",
      "Epoch 26/50\n",
      "34646/34646 [==============================] - 231s 7ms/step - loss: 0.0022 - accuracy: 0.9992 - val_loss: 0.0983 - val_accuracy: 0.9891\n",
      "Epoch 27/50\n",
      "34646/34646 [==============================] - 213s 6ms/step - loss: 0.0015 - accuracy: 0.9994 - val_loss: 0.1012 - val_accuracy: 0.9888\n",
      "Epoch 28/50\n",
      "34646/34646 [==============================] - 212s 6ms/step - loss: 0.0033 - accuracy: 0.9987 - val_loss: 0.1016 - val_accuracy: 0.9879\n",
      "Epoch 29/50\n",
      "34646/34646 [==============================] - 211s 6ms/step - loss: 0.0036 - accuracy: 0.9985 - val_loss: 0.0907 - val_accuracy: 0.9887\n",
      "Epoch 30/50\n",
      "34646/34646 [==============================] - 211s 6ms/step - loss: 0.0026 - accuracy: 0.9991 - val_loss: 0.0958 - val_accuracy: 0.9882\n",
      "Epoch 31/50\n",
      "34646/34646 [==============================] - 211s 6ms/step - loss: 0.0029 - accuracy: 0.9991 - val_loss: 0.1003 - val_accuracy: 0.9885\n",
      "Epoch 32/50\n",
      "34646/34646 [==============================] - 211s 6ms/step - loss: 0.0024 - accuracy: 0.9992 - val_loss: 0.0949 - val_accuracy: 0.9882\n",
      "Epoch 33/50\n",
      "34646/34646 [==============================] - 212s 6ms/step - loss: 0.0016 - accuracy: 0.9994 - val_loss: 0.0914 - val_accuracy: 0.9895\n",
      "Epoch 34/50\n",
      "34646/34646 [==============================] - 214s 6ms/step - loss: 0.0030 - accuracy: 0.9988 - val_loss: 0.0894 - val_accuracy: 0.9888\n",
      "Epoch 35/50\n",
      "34646/34646 [==============================] - 225s 6ms/step - loss: 0.0023 - accuracy: 0.9990 - val_loss: 0.0887 - val_accuracy: 0.9891\n",
      "Epoch 36/50\n",
      "34646/34646 [==============================] - 236s 7ms/step - loss: 0.0024 - accuracy: 0.9991 - val_loss: 0.0947 - val_accuracy: 0.9881\n",
      "Epoch 37/50\n",
      "34646/34646 [==============================] - 255s 7ms/step - loss: 0.0019 - accuracy: 0.9991 - val_loss: 0.0950 - val_accuracy: 0.9882\n",
      "Epoch 38/50\n",
      "34646/34646 [==============================] - 244s 7ms/step - loss: 9.4406e-04 - accuracy: 0.9996 - val_loss: 0.1042 - val_accuracy: 0.9876\n",
      "Epoch 39/50\n",
      "34646/34646 [==============================] - 234s 7ms/step - loss: 0.0014 - accuracy: 0.9994 - val_loss: 0.1061 - val_accuracy: 0.9871\n",
      "Epoch 40/50\n",
      "34646/34646 [==============================] - 223s 6ms/step - loss: 0.0027 - accuracy: 0.9989 - val_loss: 0.0981 - val_accuracy: 0.9873\n",
      "Epoch 41/50\n",
      "34646/34646 [==============================] - 212s 6ms/step - loss: 0.0013 - accuracy: 0.9995 - val_loss: 0.0904 - val_accuracy: 0.9890\n",
      "Epoch 42/50\n",
      "34646/34646 [==============================] - 212s 6ms/step - loss: 0.0010 - accuracy: 0.9995 - val_loss: 0.0986 - val_accuracy: 0.9873\n",
      "Epoch 43/50\n",
      "34646/34646 [==============================] - 211s 6ms/step - loss: 0.0014 - accuracy: 0.9994 - val_loss: 0.1020 - val_accuracy: 0.9879\n",
      "Epoch 44/50\n",
      "34646/34646 [==============================] - 212s 6ms/step - loss: 0.0015 - accuracy: 0.9995 - val_loss: 0.1018 - val_accuracy: 0.9887\n",
      "Epoch 45/50\n",
      "34646/34646 [==============================] - 211s 6ms/step - loss: 0.0011 - accuracy: 0.9995 - val_loss: 0.0965 - val_accuracy: 0.9901\n",
      "Epoch 46/50\n",
      "34646/34646 [==============================] - 213s 6ms/step - loss: 9.9773e-04 - accuracy: 0.9995 - val_loss: 0.1035 - val_accuracy: 0.9885\n",
      "Epoch 47/50\n",
      "34646/34646 [==============================] - 213s 6ms/step - loss: 0.0015 - accuracy: 0.9995 - val_loss: 0.1101 - val_accuracy: 0.9871\n",
      "Epoch 48/50\n",
      "34646/34646 [==============================] - 211s 6ms/step - loss: 0.0020 - accuracy: 0.9992 - val_loss: 0.0988 - val_accuracy: 0.9896\n",
      "Epoch 49/50\n",
      "34646/34646 [==============================] - 212s 6ms/step - loss: 0.0012 - accuracy: 0.9995 - val_loss: 0.1092 - val_accuracy: 0.9886\n",
      "Epoch 50/50\n",
      "34646/34646 [==============================] - 211s 6ms/step - loss: 9.6909e-04 - accuracy: 0.9996 - val_loss: 0.1039 - val_accuracy: 0.9893\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7fde2ebff128>"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs = 50\n",
    "batch_size = 128\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(train_x, train_y, validation_data=(val_x, val_y), epochs=epochs, batch_size=batch_size, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2191/2191 [==============================] - 4s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict_classes(X_test, batch_size=batch_size, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>136</td>\n",
       "      <td>275</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>122</td>\n",
       "      <td>939</td>\n",
       "      <td>164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>40</td>\n",
       "      <td>321</td>\n",
       "      <td>126</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2\n",
       "0  136  275   68\n",
       "1  122  939  164\n",
       "2   40  321  126"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(confusion_matrix(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5481515289821999"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.35006435, 0.68043478, 0.29822485])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test, predictions, average=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rápida conclusão\n",
    "\n",
    "Nesse desafio, vimos como realizar a implementação de uma rede neural recorrente capaz de prever sentimentos de reviews.\n",
    "\n",
    "Para uma boa implementação de um modelo como este, são necessárias três etapas importantes: A de organização e limpeza de dados, a escolha da arquitetura, e a fase de treinamento e validação. \n",
    "\n",
    "Por fim, é possivel aprimorarmos a rede se utilizarmos mais camadas internas da LSTM, ou também se utilizarmos um maior número de dados de treinamento. Para isto seria necessário desprender maior tempo para a tabulação de outros tweets. É possível também treinarmos uma camada de embedding separadamente da rede recorrente, utilizando um vocabulário mais completo.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
